{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TumorCellStatePrediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FwkLJrdjjFEs",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "8f06a9a9-c639-42a4-fdf4-6ff8329e8f29"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8b23772-686b-4d96-9ba4-696772f972a6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c8b23772-686b-4d96-9ba4-696772f972a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving reduced_mnist.csv to reduced_mnist (1).csv\n",
            "Saving test_wbcd.csv to test_wbcd (1).csv\n",
            "Saving train_wbcd.csv to train_wbcd (1).csv\n",
            "User uploaded file \"reduced_mnist.csv\" with length 4610614 bytes\n",
            "User uploaded file \"test_wbcd.csv\" with length 4499 bytes\n",
            "User uploaded file \"train_wbcd.csv\" with length 21924 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AAQ8vYIvmDvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Created by **Akib Mashrur** *\n",
        "\n",
        "\n",
        "In the first cell all relevant modules have been imported."
      ]
    },
    {
      "metadata": {
        "id": "_xkPESQgXz3T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Importing relevant modules ###\n",
        "\n",
        "## Data Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "## Sklearn Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Performance Measures\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "## Visualisation\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZQvTIw-pO40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Part A**\n",
        "\n",
        "*1.1 Data Munging*\n",
        "\n",
        "• Read the training and testing data. Print the number of features in the dataset.\n",
        "\n",
        "• For the data label, print the total number of 1's and 0's in the training and testing data. Comment on the class\n",
        "distribution. Is it balanced or unbalanced?\n",
        "\n",
        "• Print the number of features with missing entries.\n",
        "\n",
        "• Fill the missing entries. For filling any feature, you can use either mean or median value of the feature values\n",
        "from observed entries.\n",
        "\n",
        "• Normalize the training and testing data."
      ]
    },
    {
      "metadata": {
        "id": "0Ro9W0MSXz3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "f89dd464-7ee5-432a-80db-ee7fe8df8144"
      },
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "##### Criteria 1 #####\n",
        "## Read the training and testing data. Print the number of features in the dataset\n",
        "\n",
        "train = pd.read_csv(\"train_wbcd.csv\")\n",
        "test = pd.read_csv(\"test_wbcd.csv\")\n",
        "\n",
        "dataset = pd.concat([train,test])\n",
        "\n",
        "# We can see from the dataset all the feature columns starts with \"f\"\n",
        "features = dataset.filter(regex='[f]', axis=1)\n",
        "number_of_examples, number_of_features = features.shape\n",
        "print(f\"The number of features in the dataset are: {number_of_features}\")\n",
        "\n",
        "features.head()\n",
        "\n",
        "## For the data label, print the total number of 1's and 0's in the training and testing data. \n",
        "\n",
        "# Label Encoding Datset for analyzing distribution and creating Regression Model\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(dataset['Diagnosis'])\n",
        "dataset['TARGET'] = le.transform(dataset['Diagnosis'])\n",
        "\n",
        "print(dataset['TARGET'].value_counts())\n",
        "\n",
        "## Comment on the class distribution. Is it balanced or unbalanced?\n",
        "dataset['TARGET'].astype(int).plot.hist()\n",
        "\n",
        "## Print the number of features with missing entries\n",
        "\n",
        "# Function to calculate missing values by column \n",
        "def missing_values_table(df):\n",
        "        # Total missing values\n",
        "        mis_val = df.isnull().sum()\n",
        "        \n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        \n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        \n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        \n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "        \n",
        "        # Print some summary information\n",
        "        print (\"Selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
        "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "              \" columns that have missing values.\")\n",
        "        \n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns\n",
        "    \n",
        "missing_values = missing_values_table(dataset)\n",
        "print(missing_values)\n",
        "\n",
        "\n",
        "# Replacing missing values with mean\n",
        "dataset['f21'].fillna(dataset['f21'].mean(), inplace = True)\n",
        "\n",
        "## Normalizing the training and testing data\n",
        "\n",
        "# Only keeping the features and target attribute for the dataset \n",
        "dataset_filtered = dataset.iloc[:,2:]\n",
        "\n",
        "# Normalizing both train and test data based on z-transformation\n",
        "dataset_scaled = preprocessing.scale(dataset_filtered)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of features in the dataset are: 30\n",
            "0    72\n",
            "1    48\n",
            "Name: TARGET, dtype: int64\n",
            "Selected dataframe has 33 columns.\n",
            "There are 1 columns that have missing values.\n",
            "     Missing Values  % of Total Values\n",
            "f21               3                2.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb5af488e10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1XiAgjBqpuQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Explanation: **\n",
        "\n",
        "The total number of features in the dataset are 30. We can see based on the merged dataset the the label is moderately imbalanced. There are 72 benign cases (0) and 48 malignant cases (1). \n",
        "\n",
        "Also, there is once column with missing values. The missing values have been replaced using the mean of overall column.\n"
      ]
    },
    {
      "metadata": {
        "id": "lPqWLyeoqW07",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*1.2 Logistic Regression* \n",
        "\n",
        "Train logistic regression models with L1 regularization and L2 regularization using alpha = 0.1\n",
        "and lambda = 0.1. Report accuracy, precision, recall, f1-score and print the confusion matrix."
      ]
    },
    {
      "metadata": {
        "id": "6fqKZ1hZXz3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f04aa9f3-0bf7-4d9e-84df-929cdd927af8"
      },
      "cell_type": "code",
      "source": [
        "##### Criteria 2 #####\n",
        "\n",
        "# Seperating the data into predictors/ Response and splitting them into train/test as per original order\n",
        "\n",
        "# Predictors\n",
        "X_train = dataset.iloc[0:100,2:32]\n",
        "X_test = dataset.iloc[100:121,2:32]\n",
        "\n",
        "# Labels\n",
        "y_train = dataset.iloc[0:100,32:]\n",
        "y_test = dataset.iloc[100:121,32:]\n",
        "\n",
        "\n",
        "## Train logistic regression with L1 regularization using alpha = .1\n",
        "\n",
        "alpha_val = 0.1\n",
        "lr1 = LogisticRegression(C= 1/alpha_val, penalty='l1')\n",
        "lr1_model = lr1.fit(X_train,y_train)\n",
        "\n",
        "## Train logistic regression with L2 regularization using lambda = .1\n",
        "\n",
        "lambda_val = 0.1\n",
        "lr2 = LogisticRegression(C= 1/lambda_val, penalty='l2',)\n",
        "lr2_model = lr2.fit(X_train,y_train)\n",
        "\n",
        "## Train logistic regression using Elastic Net (Both L1 and L2 together)\n",
        "\n",
        "lr3 = SGDClassifier(loss='log', penalty='elasticnet', alpha = alpha_val, l1_ratio=0.5, max_iter=1000,random_state=2018)\n",
        "lr3_model = lr3.fit(X_train,y_train)\n",
        "\n",
        "## Evaluating both the models\n",
        "\n",
        "y_predict_l1 = lr1_model.predict(X_test)\n",
        "y_predict_l2 = lr2_model.predict(X_test)\n",
        "y_predict_l3 = lr3_model.predict(X_test)\n",
        "\n",
        "# Accuracy Scores\n",
        "# print(\"Accuracy Scores:\")\n",
        "model_acc_l1 = accuracy_score(y_predict_l1, y_test)*100\n",
        "model_acc_l2 = accuracy_score(y_predict_l2, y_test)*100\n",
        "model_acc_l3 = accuracy_score(y_predict_l3, y_test)*100\n",
        "\n",
        "accuracies = pd.Series(list((model_acc_l1,model_acc_l2,model_acc_l3)))\n",
        "\n",
        "# Precision Scores\n",
        "# print(\"Precision Scores:\")\n",
        "model_prec_l1 = precision_score(y_predict_l1, y_test)*100\n",
        "model_prec_l2 = precision_score(y_predict_l2, y_test)*100\n",
        "model_prec_l3 = precision_score(y_predict_l3, y_test)*100\n",
        "\n",
        "precisions = pd.Series(list((model_prec_l1,model_prec_l2,model_prec_l3)))\n",
        "\n",
        "# Recall Scores\n",
        "\n",
        "model_rec_l1 = recall_score(y_predict_l1, y_test)\n",
        "model_rec_l2 = recall_score(y_predict_l2, y_test)\n",
        "model_rec_l3 = recall_score(y_predict_l3, y_test)\n",
        "\n",
        "recalls = pd.Series(list((model_rec_l1,model_rec_l2,model_rec_l3)))\n",
        "\n",
        "# f1 Scores\n",
        "\n",
        "model_f1_l1 = f1_score(y_predict_l1, y_test)\n",
        "model_f1_l2 = f1_score(y_predict_l2, y_test)\n",
        "model_f1_l3 = f1_score(y_predict_l3, y_test)\n",
        "\n",
        "f1 = pd.Series(list((model_f1_l1,model_f1_l2,model_f1_l3)))\n",
        "\n",
        "\n",
        "# Confusion Metrices\n",
        "\n",
        "model_cm_l1 = confusion_matrix(y_predict_l1, y_test)\n",
        "print(f\"Confusion matrix for L1 model is: \\n{model_cm_l1}\")\n",
        "model_cm_l2 = confusion_matrix(y_predict_l2, y_test)\n",
        "print(f\"Confusion matrix for L2 model is: \\n{model_cm_l2}\")\n",
        "model_cm_l3 = confusion_matrix(y_predict_l3, y_test)\n",
        "print(f\"Confusion matrix for Elastic Net is: \\n{model_cm_l3}\")\n",
        "\n",
        "performance_matrix = pd.DataFrame()\n",
        "\n",
        "performance_matrix['model'] = pd.Series(list(('L1', 'L2', 'Elastic Net')))\n",
        "performance_matrix['accuracy'] = accuracies\n",
        "performance_matrix['precision'] = precisions\n",
        "performance_matrix['recall'] = recalls\n",
        "performance_matrix['f1'] = f1\n",
        "\n",
        "performance_matrix\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix for L1 model is: \n",
            "[[12  1]\n",
            " [ 2  5]]\n",
            "Confusion matrix for L2 model is: \n",
            "[[12  1]\n",
            " [ 2  5]]\n",
            "Confusion matrix for Elastic Net is: \n",
            "[[14  2]\n",
            " [ 0  4]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1</td>\n",
              "      <td>85.0</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L2</td>\n",
              "      <td>85.0</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Elastic Net</td>\n",
              "      <td>90.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         model  accuracy  precision    recall        f1\n",
              "0           L1      85.0  83.333333  0.714286  0.769231\n",
              "1           L2      85.0  83.333333  0.714286  0.769231\n",
              "2  Elastic Net      90.0  66.666667  1.000000  0.800000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "AYs07uDGcrMP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Explanation**\n",
        "\n",
        "We can see from the performance matrix above that Elastic Net performs best when it comes to accuracy, however it is not as precise as the L1 and L2 model."
      ]
    },
    {
      "metadata": {
        "id": "xeCcKqh_eKZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.3 Choosing the best hyper-parameter:**\n",
        "\n",
        "\n",
        "To choose the best hyperparameter (alpha/lambda) value, you have to do the following was done:\n",
        "\n",
        "• For each value of hyperparameter, performed 100 random splits of training data into training and validation\n",
        "data.\n",
        "\n",
        "• Found the average validation accuracy for each 100 train/validate pairs.\n",
        "\n",
        "The best hyperparameter was chosen with the maximum validation accuracy. Using the best alpha and lambda parameter, a new models were re-trained. \n",
        "\n",
        "Also evaluated the prediction performance on the test data and report the following:\n",
        "\n",
        "• Precision\n",
        "\n",
        "• Accuracy\n",
        "\n",
        "• The top 5 features selected in decreasing order of feature weights.\n",
        "\n",
        "• Confusion matrix\n",
        "\n",
        "Finally, it was explained whether we have build underfit or overfit models."
      ]
    },
    {
      "metadata": {
        "id": "tNNH0z16Xz3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "75b6d013-02e2-4e25-d4bc-090ea0e0041b"
      },
      "cell_type": "code",
      "source": [
        "# Building a function to calculate model accuracy in every iteration\n",
        "\n",
        "def runLRmodel(trials, train_data, penalty_type, penalty_score):\n",
        "\n",
        "   model_acc     = 0\n",
        "   model_weights = np.zeros([1,31])\n",
        "\n",
        "   for i in range(0,trials):\n",
        "      Dtrain, Dtest = train_test_split(data, test_size=0.3)\n",
        "      lr = LogisticRegression(C=1/penalty_score, penalty=penalty_type)\n",
        "      lr.fit(Dtrain.iloc[:,0:30], Dtrain.iloc[:,30:])\n",
        "      y_predict = lr.predict(X_test)\n",
        "      model_acc += accuracy_score(y_predict, y_test)\n",
        "      model_weights += np.append(lr.intercept_, lr.coef_)\n",
        "\n",
        "   model_acc /= trials\n",
        "   model_weights /= trials\n",
        "\n",
        "   return np.round(model_acc, decimals=2), np.round(model_weights,decimals=2)\n",
        "\n",
        "# Identifying the best Alpha value\n",
        "\n",
        "data = pd.concat([X_train,y_train], axis = 1)\n",
        "alpha_vals = [.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
        "l1_acc = np.zeros(len(alpha_vals))\n",
        "index = 0\n",
        "# L1 regularization\n",
        "for l in alpha_vals:\n",
        "   l1_acc[index], w = runLRmodel(100,data, 'l1', np.float(l))\n",
        "   index += 1\n",
        "\n",
        "print(\"Acc: {}\".format(l1_acc))\n",
        "# penalty at which validation accuracy is maximum\n",
        "max_index_l1  = np.argmax(l1_acc)\n",
        "best_alpha = alpha_vals[max_index_l1]\n",
        "print(\"Best Alpha: {}\".format(best_alpha))\n",
        "\n",
        "# Building a new linear regression model based on best alpha\n",
        "\n",
        "lr_alpha = LogisticRegression(C= 1/best_alpha, penalty='l1')\n",
        "lr_alpha_model = lr_alpha.fit(X_train,y_train)\n",
        "\n",
        "# Predicting on test dataset\n",
        "\n",
        "y_predict_alpha = lr_alpha_model.predict(X_test)\n",
        "\n",
        "# Accuracy Scores\n",
        "\n",
        "model_acc_best_l1 = accuracy_score(y_predict_alpha, y_test)*100\n",
        "print(f\"Accuracy for model with best alpha is {model_acc_best_l1}%\")\n",
        "\n",
        "# Precision Scores\n",
        "\n",
        "model_prec_best_l1 = precision_score(y_predict_alpha, y_test)*100\n",
        "print(f\"Precision for model with best alpha is {model_prec_best_l1}%\")\n",
        "\n",
        "# Confusion Metrices\n",
        "\n",
        "model_cm_best_l1 = confusion_matrix(y_predict_alpha, y_test)\n",
        "print(f\"Confusion Matrix for model with best alpha is: \\n {model_cm_best_l1}\")\n",
        "\n",
        "# Top 5 features (Sorted)\n",
        "\n",
        "feature_weights=lr_alpha_model.coef_[0]\n",
        "Weight_matrix = pd.DataFrame()\n",
        "Weight_matrix['Feature'] = pd.Series(list(features.columns.values))\n",
        "Weight_matrix['Weights'] = pd.Series(feature_weights,name= \"Weights\")\n",
        "Weight_matrix['Abs Weights'] = abs(Weight_matrix['Weights'])\n",
        "\n",
        "Weight_matrix.sort_values('Abs Weights',ascending = False).head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: [0.83 0.84 0.82 0.89 0.92 0.92 0.93 0.31 0.3  0.48 0.7 ]\n",
            "Best Alpha: 333\n",
            "Accuracy for model with best alpha is 95.0%\n",
            "Precision for model with best alpha is 83.33333333333334%\n",
            "Confusion Matrix for model with best alpha is: \n",
            " [[14  1]\n",
            " [ 0  5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Weights</th>\n",
              "      <th>Abs Weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f3</td>\n",
              "      <td>-0.037094</td>\n",
              "      <td>0.037094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>f24</td>\n",
              "      <td>0.008297</td>\n",
              "      <td>0.008297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f4</td>\n",
              "      <td>-0.005506</td>\n",
              "      <td>0.005506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>f17</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Feature   Weights  Abs Weights\n",
              "2       f3 -0.037094     0.037094\n",
              "23     f24  0.008297     0.008297\n",
              "3       f4 -0.005506     0.005506\n",
              "0       f1  0.000000     0.000000\n",
              "16     f17  0.000000     0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "kbKZjMcmXz3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d821cd9b-1bff-41a0-82bf-8ffbfc3bfd28"
      },
      "cell_type": "code",
      "source": [
        "# instantiating needed lists\n",
        "\n",
        "lambda_vals = [.001,.003,.01,.03,.1,.3,1,3,10,33]\n",
        "l2_acc = np.zeros(len(lambda_vals))\n",
        "index = 0\n",
        "# L2 regularization\n",
        "for l in lambda_vals:\n",
        "   l2_acc[index], w = runLRmodel(100,data, 'l2', np.float(l))\n",
        "   index += 1\n",
        "\n",
        "print(\"Acc: {}\".format(l2_acc))\n",
        "# penalty at which validation accuracy is maximum\n",
        "max_index_l2  = np.argmax(l2_acc)\n",
        "best_lambda = lambda_vals[max_index_l2]\n",
        "print(\"Best Lambda: {}\".format(best_lambda))\n",
        "\n",
        "# Building a new linear regression model based on best lambda\n",
        "\n",
        "lr_lambda = LogisticRegression(C= 1/best_lambda, penalty='l2')\n",
        "lr_lambda_model = lr_lambda.fit(X_train,y_train)\n",
        "\n",
        "# Predicting on test dataset\n",
        "\n",
        "y_predict_lambda = lr_lambda_model.predict(X_test)\n",
        "\n",
        "# Accuracy Scores\n",
        "\n",
        "model_acc_best_l2 = accuracy_score(y_predict_lambda, y_test)*100\n",
        "print(f\"Accuracy for model with best lambda is {model_acc_best_l2}%\")\n",
        "\n",
        "#Precision Scores\n",
        "\n",
        "model_prec_best_l2 = precision_score(y_predict_lambda, y_test)*100\n",
        "print(f\"Precision for model with best lambda is {model_prec_best_l2}%\")\n",
        "\n",
        "#Confusion Metrices\n",
        "\n",
        "model_cm_best_l2 = confusion_matrix(y_predict_lambda, y_test)\n",
        "print(f\"Confusion Matrix for model with best lambda is: \\n {model_cm_best_l2}\")\n",
        "\n",
        "#Top 5 features (Sorted)\n",
        "\n",
        "feature_weights_lambda=lr_lambda_model.coef_[0]\n",
        "Weight_matrix_lambda = pd.DataFrame()\n",
        "Weight_matrix_lambda['Feature'] = pd.Series(list(features.columns.values))\n",
        "Weight_matrix_lambda['Weights'] = pd.Series(feature_weights_lambda,name= \"Weights\")\n",
        "Weight_matrix_lambda['Abs Weights'] = abs(Weight_matrix_lambda['Weights'])\n",
        "\n",
        "Weight_matrix_lambda.sort_values('Abs Weights',ascending = False).head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: [0.83 0.83 0.83 0.83 0.83 0.84 0.83 0.84 0.82 0.83]\n",
            "Best Lambda: 0.3\n",
            "Accuracy for model with best lambda is 85.0%\n",
            "Precision for model with best lambda is 83.33333333333334%\n",
            "Confusion Matrix for model with best lambda is: \n",
            " [[12  1]\n",
            " [ 2  5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Weights</th>\n",
              "      <th>Abs Weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f1</td>\n",
              "      <td>-2.079512</td>\n",
              "      <td>2.079512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>f21</td>\n",
              "      <td>-1.477307</td>\n",
              "      <td>1.477307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>f27</td>\n",
              "      <td>1.078841</td>\n",
              "      <td>1.078841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>f26</td>\n",
              "      <td>0.851103</td>\n",
              "      <td>0.851103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f3</td>\n",
              "      <td>-0.815760</td>\n",
              "      <td>0.815760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Feature   Weights  Abs Weights\n",
              "0       f1 -2.079512     2.079512\n",
              "20     f21 -1.477307     1.477307\n",
              "26     f27  1.078841     1.078841\n",
              "25     f26  0.851103     0.851103\n",
              "2       f3 -0.815760     0.815760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "E-DlFpsGgq5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "Based on the above two model accuracies with best alpha/ lambda values, we can see that L1 regularized model with alpha 333 gives us the best accuracy of 95% which is higher than the average validation accuracy score of 85%. Also, there is no sign of underfitting/ overfitting since the accuracy was tested on an unseen test data and still maintains a moderately high accuracy.\n",
        "\n",
        "However, it should be noted that since it is apparently a cancer classification dataset, precision might be a more important performance indicator than accuracy, but alarmingly, we have a relatively low precision (83.33%). We need to evaluate building better models in this case."
      ]
    },
    {
      "metadata": {
        "id": "eCS1AVXijT6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Part A ends here ##"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}